from skimage.util import img_as_float, img_as_ubyte
import numpy as np
from scipy.spatial import distance


########################################
##Pixelwise Ops


#NEEDS FLOATS AS INPUT IN DESIRED VALUES
def histogram_stretch(img_in, min_desired, max_desired):

    # img_as_float will divide all pixel values with 255.0
    img_float = img_as_float(img_in)
    min_val = img_float.min()
    max_val = img_float.max()

    img_out = (max_desired - min_desired) / (max_val - min_val) * (img_in - min_val) + min_desired

    # img_as_ubyte will multiply all pixel values with 255.0 before converting to unsigned byte
    return img_as_ubyte(img_out)

"""
plt.hist(im_s.ravel(), bins=256)
plt.title('Image histogram')
io.show()

io.imshow(im_s)
io.show()
"""


#g(x,y) = f(x,y)^gamma
def gamma_map(img, gamma):
    img_float = img_as_float(img)
    out = img_as_ubyte(np.power(img_float, gamma))
    return out


#########################################################3
#Pixel classification

"""
norm.pdf(x, mean, std)
e.g. norm.pdf(38, loc=32.3, scale=7.87)
"""

def minimum_distance_threshold(img1, img2):
    return (np.mean(img1) + np.mean(img2))/2

"""
Parametric pixel classification
- Make normal dist for each image to which the pixel can belong to
- do norm.pdf(pixel) and select the image with that gives the highest prob

Segmentation:
fat_img = (img > t_background) & (img <= t_fat_soft)

spleen_mask = spleen_roi > 0
spleen_values = img[spleen_mask]
"""

#Measures similarity between 2 binary images
#Images need to be binary
#Usually the gt will need to be binarized with > 0
def dice_score(img1, ground_truth):
    dice = 1 - distance.dice(img1.ravel(), ground_truth.ravel())
    return dice


#############################################
#Advanced pixel classification

"""
Linear discriminant analysis (LDA)

w = np.linalg.inv(covariance_matrix) @ (mean2 - mean1)

c = ln(P1/P2) - 0.5(mean2 + mean1).T

w0 = c @ w

y(x belongs to class 2) = x.T @ w + w0
if > 0 then x belongs to class 2 else class 1
"""

#X is training data, y is 0000000111111111
def LDA(X, y):
    """
    Linear Discriminant Analysis.

    A classifier with a linear decision boundary, generated by fitting class conditional densities to the data and using Bayesâ€™ rule.
    Assumes equal priors among classes

    Parameters
    ----------
    X : array-like of shape (n_samples, n_features)
        Training data
    y : array-like of shape (n_samples,)
        Target values.

    Returns
    -------
    W : array-like of shape (n_classes, n_features+1)
        Weights for making the projection. First column is the constants.

    Last modified: 11/11/22, mcbo@dtu.dk
    """

    # Determine size of input data
    n, m = X.shape
    # Discover and count unique class labels
    class_label = np.unique(y)
    k = len(class_label)

    # Initialize
    n_group = np.zeros((k, 1))  # Group counts
    group_mean = np.zeros((k, m))  # Group sample means
    pooled_cov = np.zeros((m, m))  # Pooled covariance
    W = np.zeros((k, m + 1))  # Model coefficients

    for i in range(k):
        # Establish location and size of each class
        group = np.squeeze(y == class_label[i])
        n_group[i] = np.sum(group.astype(np.double))

        # Calculate group mean vectors
        group_mean[i, :] = np.mean(X[group, :], axis=0)

        # Accumulate pooled covariance information
        pooled_cov = pooled_cov + ((n_group[i] - 1) / (n - k)) * np.cov(X[group, :], rowvar=False)

    # Assign prior probabilities
    prior_prob = n_group / n

    # Loop over classes to calculate linear discriminant coefficients
    for i in range(k):
        # Intermediate calculation for efficiency
        temp = group_mean[i, :][np.newaxis] @ np.linalg.inv(pooled_cov)

        # Constant
        W[i, 0] = -0.5 * temp @ group_mean[i, :].T + np.log(prior_prob[i])

        # Linear
        W[i, 1:] = temp

    return W


def predict_LDA(W, X):
    # Add bias term
    # Adds 1, 1 for multiplying c w0
    X_aug = np.hstack((np.ones((X.shape[0], 1)), X))
    # Compute linear discriminant scores
    scores = X_aug @ W.T
    # Predict class with highest score
    return np.argmax(scores, axis=1)
